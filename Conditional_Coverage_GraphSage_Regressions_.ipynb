{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9GTWWXJ/N/xM7Evk5MjuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caltdreamer/GNN/blob/main/Conditional_Coverage_GraphSage_Regressions_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Conditional Calibration Package\n",
        "pip install conditionalconformal"
      ],
      "metadata": {
        "id": "oRpHmcRj8Ygh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa7_gM6R_Hh9"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install -q torch-geometric\n",
        "!pip install umap-learn\n",
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GraphSAGE\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.datasets import NELL\n",
        "from torch_geometric.datasets import CitationFull\n",
        "from torch_geometric.datasets import CoraFull\n",
        "from torch_geometric.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import random\n",
        "import networkx as nx\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from conditionalconformal.synthetic_data import generate_cqr_data, indicator_matrix\n",
        "from conditionalconformal import CondConf\n",
        "\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "9ngMu5UK__-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Construct Data (X,Y) 1-d case for better illustrations\n",
        "\n",
        "\n",
        "def generate_cqr_data(seed,n_train,n_calib,n_test):\n",
        "\n",
        "\n",
        "    n_train = n_train + n_calib\n",
        "\n",
        "    def f(x):\n",
        "\n",
        "        ax = 0*x\n",
        "        for i in range(len(x)):\n",
        "            ax[i] = np.random.poisson(np.sin(x[i])**2+0.1) + 0.03*x[i]*np.random.randn(1)\n",
        "            ax[i] += 10*(np.random.uniform(0,1,1)<0.01)*np.random.randn(1)\n",
        "        return ax.astype(np.float32)\n",
        "\n",
        "    #x sampled from uniform[0,5] for better visualizing\n",
        "    x_train = np.random.uniform(0, 5.0, size=n_train).astype(np.float32)\n",
        "\n",
        "\n",
        "    x_test = np.random.uniform(0, 5.0, size=n_test).astype(np.float32)\n",
        "\n",
        "    y_train = f(x_train)\n",
        "    y_test = f(x_test)\n",
        "\n",
        "\n",
        "    x_train = np.reshape(x_train,(n_train,1))\n",
        "    x_test = np.reshape(x_test,(n_test,1))\n",
        "\n",
        "    train_set_size = len(y_train) - n_calib\n",
        "    x_train_final = x_train[ : train_set_size]\n",
        "    x_calib = x_train[train_set_size : ]\n",
        "    y_train_final = y_train[ : train_set_size]\n",
        "    y_calib = y_train[train_set_size : ]\n",
        "\n",
        "    return x_train_final, y_train_final, x_calib, y_calib, x_test, y_test\n",
        "\n",
        "#To indicate which data belongs to which group\n",
        "#Data is row and column represents groups\n",
        "def indicator_matrix(scalar_values, disc):\n",
        "    scalar_values = np.array(scalar_values)\n",
        "\n",
        "\n",
        "    intervals = [(disc[i], disc[i + 1]) for i in range(len(disc) - 1)]\n",
        "\n",
        "\n",
        "    matrix = np.zeros((len(scalar_values), len(intervals)))\n",
        "\n",
        "    for i, value in enumerate(scalar_values):\n",
        "        for j, (a, b) in enumerate(intervals):\n",
        "            if a <= value < b:\n",
        "                matrix[i, j] = 1\n",
        "\n",
        "    return matrix\n"
      ],
      "metadata": {
        "id": "9e0eauuZy31V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = 1500\n",
        "n_calib = 500\n",
        "n_test = 500\n",
        "x_train_final, y_train_final, x_calib, y_calib, x_test, y_test = generate_cqr_data(30,n_train,n_calib,n_test)"
      ],
      "metadata": {
        "id": "7y1XKR2ZzTCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x_test, y_test, color='red', marker='o', label='Data Points')\n",
        "\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.title('Scatter Plot of (x,y) Points')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TmMwEa2CGBEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_all = np.concatenate((x_train_final, x_calib, x_test), axis=0)\n",
        "y_all = np.concatenate((y_train_final,y_calib,y_test),axis = 0)"
      ],
      "metadata": {
        "id": "XVcKpwBg0Uqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Erdos Renyi Graph with probability p =0.3 as the graph model\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "num_nodes = n_train+n_calib+n_test\n",
        "adj_matrix = np.random.rand(num_nodes, num_nodes) < 0.3\n",
        "np.fill_diagonal(adj_matrix, 0)\n",
        "rows, cols = np.where(adj_matrix)\n",
        "edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
        "features = torch.tensor(x_all)\n",
        "labels = torch.tensor(y_all)\n",
        "\n",
        "data = Data(x=features, edge_index=edge_index, y=labels)\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBnyASh-ywLP",
        "outputId": "15771041-3cf9-47e5-f571-627613b4a793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2500, 1], edge_index=[2, 1874074], y=[2500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data)\n",
        "print(data.x)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = data.x.to(device)\n",
        "y = data.y.squeeze().to(device)\n"
      ],
      "metadata": {
        "id": "mtWZAZnr__6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(100)"
      ],
      "metadata": {
        "id": "dFmguIYvl4vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train would be first 1500, calibration 1501-2000,test 2001-2500\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[list(range(n_train))] = True\n",
        "cali_mask = torch.zeros(num_nodes,dtype=torch.bool)\n",
        "cali_mask[list(range(n_train,n_train+n_calib))] = True\n",
        "test_mask = torch.zeros(num_nodes,dtype=torch.bool)\n",
        "test_mask[list(range(n_train+n_calib,n_train+n_calib+n_test))] = True\n",
        "print(train_mask.sum())\n",
        "print(test_mask.sum())\n",
        "print(cali_mask.sum())"
      ],
      "metadata": {
        "id": "WtPecMVB2BVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = NeighborSampler(\n",
        "    data.edge_index, node_idx=train_mask,\n",
        "    sizes=[5,5,5], batch_size=(n_train+1), shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "id": "0redTlMj__1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self,in_channels,hidden_channels,out_channels,num_layers = 3):\n",
        "        super(SAGE,self).__init__()\n",
        "\n",
        "        self.numlayers = num_layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels,hidden_channels))\n",
        "        for i in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels,hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels,out_channels))\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "    def forward(self,x,adjs):\n",
        "        for i ,(edge_index,_,size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]#x should be a list prioritizing target nodes\n",
        "            x = self.convs[i]((x,x_target),edge_index)\n",
        "            if i != self.numlayers -1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x,p=0.5,training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
        "#To see the performance on using whole neighborhood edges with three layers\n",
        "    def inference(self, x,adjs):\n",
        "        for i ,(edge_index,_,size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]#x should be a list prioritizing target nodes\n",
        "            x = self.convs[i]((x,x_target),edge_index)\n",
        "            if i != self.numlayers -1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x,p=0.5,training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n"
      ],
      "metadata": {
        "id": "DAx3shN2__zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SAGE(data.num_features, 2, 1, num_layers=3)\n",
        "\n",
        "model.reset_parameters()\n",
        "#We only input the initializing variables\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "v2-thI7s__xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "CD9d_m6-P9kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    i=0\n",
        "    for batch_size,n_id,adjs in train_loader:\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "        optimizer.zero_grad()\n",
        "        l1_emb, l2_emb, l3_emb = model(x[n_id], adjs)\n",
        "        loss = F.mse_loss(l3_emb,y[n_id][:batch_size].unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i+=loss\n",
        "\n",
        "    return i\n",
        "\n"
      ],
      "metadata": {
        "id": "6Bpagr0j__sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.005)\n",
        "\n",
        "for epoch in range(1,100):\n",
        "    loss = train(epoch)\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "GmK6nyQG__qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CaliGraph_loader = NeighborSampler(data.edge_index,node_idx = cali_mask\n",
        "  , sizes = [5,5,5],batch_size = 5000,shuffle=False)"
      ],
      "metadata": {
        "id": "Auta1Ox8BPWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestGraph_loader  = NeighborSampler(data.edge_index,node_idx = test_mask\n",
        "  , sizes = [5,5,5],batch_size = 5000,shuffle=False)"
      ],
      "metadata": {
        "id": "_wPOWrbgBPTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CaliandTestGraph_loader = NeighborSampler(data.edge_index,node_idx = test_mask+cali_mask\n",
        "  , sizes = [5,5,5],batch_size = 5000,shuffle=False)"
      ],
      "metadata": {
        "id": "-Ng5H4diBN0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function the takes graph loader to the third layer embedding and the fn which is\n",
        "#a matrix in the form [x,predicted y]\n",
        "def inference_1(subgraph_loader):\n",
        "    model.eval()\n",
        "    total_loss = total_correct = 0\n",
        "    for batch_size,n_id,adjs in subgraph_loader:\n",
        "\n",
        "        emb1,emb2,emb3 = model(x[n_id],adjs)\n",
        "\n",
        "        c = x[n_id][:batch_size]\n",
        "        fn = torch.cat((c, emb3), dim=1)\n",
        "\n",
        "\n",
        "    return emb3,fn\n"
      ],
      "metadata": {
        "id": "tja9Ss-GBPRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb3,fn = inference_1(CaliandTestGraph_loader)\n",
        "\n",
        "fn = fn.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "8Yhrws2wAN4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x is input vector and output is predicted label vector\n",
        "def get_xhat(x):\n",
        "  xhat= np.ones((x.shape[0], 1))\n",
        "  for j in range(x.shape[0]):\n",
        "   for i in range((cali_mask+test_mask).sum()):\n",
        "     if(x[j] == fn[i,0]).any():\n",
        "      xhat[j]=fn[i,1]\n",
        "\n",
        "  return xhat"
      ],
      "metadata": {
        "id": "LJUp-r1ZPXBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we're using score to be absolute residual\n",
        "def score_fn(x,y):\n",
        "  for i in range((cali_mask+test_mask).sum()):\n",
        "    if(x == fn[i,0]).any():\n",
        "      return y-fn[i,1]\n",
        "      break\n",
        "\n"
      ],
      "metadata": {
        "id": "t68nP51BBg18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_inv_fn_ub(s,x):\n",
        "  for i in range((cali_mask+test_mask).sum()):\n",
        "    if(x==fn[i,0]).any():\n",
        "      return [-np.inf,fn[i,1]+s]\n",
        "      break\n"
      ],
      "metadata": {
        "id": "tM0pp6up9_Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_inv_fn_lb(s,x):\n",
        "  for i in range((cali_mask+test_mask).sum()):\n",
        "    if(x==fn[i,0]).any():\n",
        "      return[fn[i,1]+s,np.inf]\n",
        "      break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CJdR_U4nAFQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#our grroup is divided into [0,0.5,1,1.5......5]\n",
        "eps = 0.5\n",
        "disc = np.arange(0, 5 + eps, eps)\n",
        "\n",
        "def phi_fn_groups(x):\n",
        "    return indicator_matrix(x, disc)\n",
        "\n",
        "\n",
        "# coverage on Gaussians with mu=loc and sd=scale\n",
        "# scale = 1 for x != [1.5, 3.5]\n",
        "eval_locs = [1.5, 3.5]\n",
        "eval_scale = 0.2\n",
        "\n",
        "other_locs = [0.5, 2.5, 4.5]\n",
        "other_scale = 1\n",
        "\n",
        "def phi_fn_shifts(x):\n",
        "    shifts = [norm.pdf(x, loc=loc, scale=eval_scale).reshape(-1,1)\n",
        "                   for loc in eval_locs]\n",
        "    shifts.extend([norm.pdf(x, loc=loc, scale=other_scale).reshape(-1,1)\n",
        "                   for loc in other_locs])\n",
        "    shifts.append(np.ones((x.shape[0], 1)))\n",
        "    return np.concatenate(shifts, axis=1)\n",
        "\n",
        "# intercept only phi_fn\n",
        "def phi_fn_intercept(x):\n",
        "    return np.ones((x.shape[0], 1))\n"
      ],
      "metadata": {
        "id": "oUao5_dCBPNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment = 'groups'\n",
        "phi_fn = phi_fn_groups\n",
        "infinite_params = {}"
      ],
      "metadata": {
        "id": "C2zR5-UdIa4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_conf = CondConf(score_fn, phi_fn, infinite_params)\n",
        "cond_conf.setup_problem(x_calib, y_calib)\n"
      ],
      "metadata": {
        "id": "cGCr_9irIa2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test = len(x_test)\n",
        "alpha = 0.1\n",
        "lbs = np.zeros((n_test,))\n",
        "ubs = np.zeros((n_test,))\n",
        "i = 0\n",
        "for x_t in tqdm(x_test):\n",
        "    res = cond_conf.predict(alpha / 2, x_t, score_inv_fn_lb)\n",
        "    lbs[i] = res[0]\n",
        "    res = cond_conf.predict(1 - alpha / 2, x_t, score_inv_fn_ub)\n",
        "    ubs[i] = res[1]\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "ySCQF0nRIa0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the quantile to produce split conformal prediction\n",
        "q = np.quantile(np.abs(get_xhat(x_calib) - y_calib),\n",
        "                np.ceil((len(x_calib) + 1) * (0.9)) / len(x_calib),)"
      ],
      "metadata": {
        "id": "eOoTEuTpUq8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(x_test)\n",
        "#print(y_test)\n",
        "\n",
        "print(get_xhat(x_test))"
      ],
      "metadata": {
        "id": "cAqLSMpkaKOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_marginalcovergage_condi():\n",
        "  j=0\n",
        "  for i in range(len(x_test)):\n",
        "    if((y_test[i]<=ubs[i]) & (y_test[i]>=lbs[i])):\n",
        "      j+=1\n",
        "\n",
        "  return j/len(x_test)\n",
        "def get_marginalcovergage_split():\n",
        "  j=0\n",
        "  x_hat = get_xhat(x_test)\n",
        "  for i in range(len(x_test)):\n",
        "    if((y_test[i]>=x_hat[i]-q )& (y_test[i]<= x_hat[i]+q)):\n",
        "      j+=1\n",
        "\n",
        "  return j/len(x_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "c0l-Lje7KmBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marginal_covergage_split = get_marginalcovergage_split()\n",
        "marginal_covergage_condi = get_marginalcovergage_condi()\n"
      ],
      "metadata": {
        "id": "E_p2IJUyKl_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(marginal_covergage_condi)\n",
        "print(marginal_covergage_split)"
      ],
      "metadata": {
        "id": "goWWaRHXKl9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "q = np.quantile(np.abs(get_xhat(x_calib) - y_calib),\n",
        "                np.ceil((len(x_calib) + 1) * (0.9)) / len(x_calib),)\n",
        "\n",
        "cp = sns.color_palette()\n",
        "sns.set(font=\"DejaVu Sans\")\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(17.5, 6)\n",
        "\n",
        "sort_order = np.argsort(x_test[0:n_test,0])\n",
        "x_test_s = x_test[sort_order]\n",
        "y_test_s = y_test[sort_order]\n",
        "y_test_hat = get_xhat(x_test[sort_order])\n",
        "lb = lbs[sort_order]\n",
        "ub = ubs[sort_order]\n",
        "\n",
        "ax1 = fig.add_subplot(1, 3, 1)\n",
        "ax1.plot(x_test_s, y_test_s, '.', alpha=0.2)\n",
        "ax1.plot(x_test_s, y_test_hat, lw=1, color='k')\n",
        "ax1.plot(x_test_s, y_test_hat + q, color=cp[0], lw=2)\n",
        "ax1.plot(x_test_s, y_test_hat - q, color=cp[0], lw=2)\n",
        "\n",
        "ax1.set_ylim(-2,6.5)\n",
        "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
        "ax1.set_xlabel(\"$X$\", fontsize=16, labelpad=10)\n",
        "ax1.set_ylabel(\"$Y$\", fontsize=16, labelpad=10)\n",
        "ax1.set_title(\"Split Conformal\", fontsize=18, pad=12)\n",
        "ax1.fill_between(x_test_s.flatten(), y_test_hat.flatten() - q, y_test_hat.flatten() + q,\n",
        "                 color=cp[0], alpha=0.4, label='split prediction interval')\n",
        "\n",
        "\n",
        "ax2 = fig.add_subplot(1, 3, 2, sharex = ax1, sharey = ax1)\n",
        "ax2.plot(x_test_s, y_test_s, '.', alpha=0.2)\n",
        "ax2.plot(x_test_s, y_test_hat, color='k', lw=1)\n",
        "ax2.plot(x_test_s, ub, color=cp[1], lw=2)\n",
        "ax2.plot(x_test_s, lb, color=cp[1], lw=2)\n",
        "ax2.fill_between(x_test_s.flatten(), lb,\n",
        "                 ub,\n",
        "                 color=cp[1], alpha=0.4, label='conditional calibration')\n",
        "ax2.tick_params(axis='both', which='major', direction='out', labelsize=14)\n",
        "ax2.set_xlabel(\"$X$\", fontsize=16, labelpad=10)\n",
        "ax2.set_ylabel(\"$Y$\", fontsize=16, labelpad=10)\n",
        "ax2.set_title(\"Conditional Calibration\", fontsize=18, pad=12)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6_CsulJOIaxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up the problem by shifts\n",
        "cond_conf = CondConf(score_fn, phi_fn_shifts, infinite_params)\n",
        "cond_conf.setup_problem(x_calib, y_calib)\n",
        "\n",
        "n_test = len(x_test)\n",
        "alpha = 0.1\n",
        "lbs = np.zeros((n_test,))\n",
        "ubs = np.zeros((n_test,))\n",
        "i = 0\n",
        "for x_t in tqdm(x_test):\n",
        "    res = cond_conf.predict(alpha / 2, x_t, score_inv_fn_lb)\n",
        "    lbs[i] = res[0]\n",
        "    res = cond_conf.predict(1 - alpha / 2, x_t, score_inv_fn_ub)\n",
        "    ubs[i] = res[1]\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "mQ3JG2ruPPYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cp = sns.color_palette()\n",
        "sns.set(font=\"DejaVu Sans\")\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(12.5, 6)\n",
        "\n",
        "\n",
        "sort_order = np.argsort(x_test[0:n_test,0])\n",
        "x_test_s = x_test[sort_order]\n",
        "y_test_s = y_test[sort_order]\n",
        "y_test_hat = get_xhat((x_test[sort_order]))\n",
        "lb_ag = lbs[sort_order]\n",
        "ub_ag = ubs[sort_order]\n",
        "\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(x_test_s, y_test_s, '.', alpha=0.2)\n",
        "ax1.plot(x_test_s, y_test_hat, lw=1, color='k')\n",
        "ax1.plot(x_test_s, ub_ag, color=cp[1], lw=2)\n",
        "ax1.plot(x_test_s, lb_ag, color=cp[1], lw=2)\n",
        "ax1.fill_between(x_test_s.flatten(), lb_ag, ub_ag,\n",
        "                 color=cp[1], alpha=0.4, label='conditional calibration')\n",
        "\n",
        "\n",
        "\n",
        "ax1.set_ylim(-2,6)\n",
        "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
        "ax1.set_xlabel(\"$X$\", fontsize=16, labelpad=10)\n",
        "ax1.set_ylabel(\"$Y$\", fontsize=16, labelpad=10)\n",
        "ax1.set_title(\"Conditional Calibration\", fontsize=18, pad=12)\n",
        "\n",
        "\n",
        "for loc in eval_locs:\n",
        "    ax1.plot(x_test_s, norm.pdf(x_test_s, loc=loc, scale=eval_scale), color='grey', ls='--', lw=3)\n"
      ],
      "metadata": {
        "id": "Qvb2VH--UMnC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}